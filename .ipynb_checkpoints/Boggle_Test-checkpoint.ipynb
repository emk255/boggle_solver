{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "70f136b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 3,\n",
       " 'b': 3,\n",
       " 'c': 3,\n",
       " 'd': 2,\n",
       " 'e': 3,\n",
       " 'f': 4,\n",
       " 'g': 2,\n",
       " 'h': 4,\n",
       " 'i': 1,\n",
       " 'j': 8,\n",
       " 'k': 5,\n",
       " 'l': 1,\n",
       " 'm': 3,\n",
       " 'n': 1,\n",
       " 'o': 1,\n",
       " 'p': 3,\n",
       " 'q': 10,\n",
       " 'r': 1,\n",
       " 's': 1,\n",
       " 't': 1,\n",
       " 'u': 1,\n",
       " 'v': 4,\n",
       " 'w': 4,\n",
       " 'x': 8,\n",
       " 'y': 4,\n",
       " 'z': 10,\n",
       " 'qu': 30}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2a225d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[(0, 2), (1, 1), (1, 3), (2, 1), (2, 3), (3, 1), (3, 2)]\n",
      "[(0, 0), (0, 1), (0, 2), (1, 1), (1, 3), (2, 1), (2, 3), (3, 1), (3, 2)]\n",
      "[(0, 0), (0, 1), (0, 2), (0, 3), (1, 1), (1, 2), (1, 3), (2, 1), (2, 3), (3, 1), (3, 2)]\n",
      "[(0, 0), (0, 1), (0, 2), (0, 3), (1, 1), (1, 2), (1, 3), (2, 1), (2, 2), (2, 3), (3, 0), (3, 1), (3, 2)]\n",
      "[(0, 0), (0, 1), (0, 2), (0, 3), (1, 1), (1, 2), (1, 3), (2, 1), (2, 2), (2, 3), (3, 0), (3, 1), (3, 2), (3, 3)]\n",
      "[(0, 0), (0, 1), (0, 2), (0, 3), (1, 1), (1, 2), (1, 3), (2, 0), (2, 1), (2, 2), (2, 3), (3, 0), (3, 1), (3, 2), (3, 3)]\n",
      "{(0, 1), (1, 2), (2, 1), (0, 0), (3, 1), (1, 1), (0, 3), (2, 0), (3, 0), (2, 3), (0, 2), (3, 3), (2, 2), (3, 2), (1, 3)}\n"
     ]
    }
   ],
   "source": [
    "class TrieNode:\n",
    "    def __init__(self):\n",
    "        self.children = {}\n",
    "        self.is_end_of_word = False\n",
    "\n",
    "class Trie:\n",
    "    def __init__(self):\n",
    "        self.root = TrieNode()\n",
    "\n",
    "    def insert(self, word):\n",
    "        node = self.root\n",
    "        for char in word:\n",
    "            if char not in node.children:\n",
    "                node.children[char] = TrieNode()\n",
    "            node = node.children[char]\n",
    "        node.is_end_of_word = True\n",
    "\n",
    "    def search(self, word):\n",
    "        node = self.root\n",
    "        for char in word:\n",
    "            if char not in node.children:\n",
    "                return False\n",
    "            node = node.children[char]\n",
    "        return node.is_end_of_word\n",
    "\n",
    "    def startsWith(self, prefix):\n",
    "        node = self.root\n",
    "        for char in prefix:\n",
    "            if char not in node.children:\n",
    "                return False\n",
    "            node = node.children[char]\n",
    "        return True\n",
    "\n",
    "def findWords(board, words):\n",
    "    def dfs(node, i, j, path, visited, indices):\n",
    "        if i < 0 or i >= len(board) or j < 0 or j >= len(board[0]) or visited[i][j]:\n",
    "            return\n",
    "        tile = board[i][j]  # This could be 'q', 'u', or 'qu'\n",
    "        new_path = path + tile  # Add the entire tile to the path\n",
    "        indices.append((i, j))  # Add the index of the current tile to the indices list\n",
    "\n",
    "        if not trie.startsWith(new_path):\n",
    "            indices.pop()  # Backtrack the index path if the current path does not lead to any word\n",
    "            return\n",
    "\n",
    "        if trie.search(new_path):  # Check if the new path is a word\n",
    "            result.add(new_path)\n",
    "            word_indices[new_path] = list(indices)  # Store a copy of the current indices path for this word\n",
    "\n",
    "        visited[i][j] = True\n",
    "        for dx, dy in [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]:\n",
    "            dfs(node, i + dx, j + dy, new_path, visited, indices)\n",
    "        visited[i][j] = False\n",
    "        indices.pop()  # Backtrack the index path when backtracking the DFS\n",
    "\n",
    "\n",
    "    trie = Trie()\n",
    "    for word in words:\n",
    "        trie.insert(word)\n",
    "\n",
    "    result = set()\n",
    "    visited = [[False]*4 for _ in range(4)]\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            dfs(trie.root, i, j, '', visited, [])\n",
    "#     print(trie)\n",
    "    return list(result)\n",
    "\n",
    "def calculate_base_score(word):\n",
    "    score = 0\n",
    "    for i in range(len(word)):\n",
    "        score+=score_chart[word[i]]\n",
    "    if len(word) >=5:\n",
    "        score +=(len(word)-4)*5\n",
    "    for (i,j) in dw_idx:\n",
    "        if (i,j) in dict(word_indices)[word]:\n",
    "            score *=2\n",
    "    for (i,j) in tw_idx:\n",
    "        if (i,j) in dict(word_indices)[word]:\n",
    "            score *=3\n",
    "    return score\n",
    "\n",
    "def calculate_unique_coverage(path, current_coverage):\n",
    "    \"\"\"Calculate how many new tiles a word's path would cover.\"\"\"\n",
    "    return len(set(path) - current_coverage)\n",
    "\n",
    "\n",
    "with open('word-list.txt') as f:\n",
    "    data = f.read().split(\"\\n\")\n",
    "word_list = [word.split(\" \")[0].lower() for word in data]\n",
    "\n",
    "score_chart = {\n",
    "    'a':1, 'b':3, 'c':3, 'd':2, 'e':1, 'f':4, 'g':2, 'h':4, 'i':1, 'j':8, 'k':5, 'l':1, 'm':3, 'n':1, 'o':1,'p':3,\n",
    "    'q':10, 'r':1, 's':1, 't':1, 'u':1, 'v':4, 'w':4, 'x':8, 'y':4, 'z':10, 'qu':10\n",
    "}\n",
    "\n",
    "board = [\n",
    "    ['y#', 'a', 's%', 'e'],\n",
    "    ['v', 'n', 't', 'h'],\n",
    "    ['r', 'o', 'y', 'i#'],\n",
    "    ['h#', 'd', 'p', 'n']\n",
    "]\n",
    "dw_idx, tw_idx = [], []\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        if '@' in board[i][j]:\n",
    "            score_chart[board[i][j].split(\"@\")[0]]*=2\n",
    "            board[i][j] = board[i][j].split(\"@\")[0]\n",
    "        if'#' in board[i][j]:\n",
    "            score_chart[board[i][j].split(\"#\")[0]]*=3\n",
    "            board[i][j] = board[i][j].split(\"#\")[0]\n",
    "        if '$' in board[i][j]:\n",
    "            dw_idx.append((i,j))\n",
    "            board[i][j] = board[i][j][0]\n",
    "        if '%' in board[i][j]:\n",
    "            tw_idx.append((i,j))\n",
    "            board[i][j] = board[i][j][0]\n",
    "            \n",
    "word_indices = {}\n",
    "r = findWords(board, word_list)\n",
    "found_words = [(key, word_indices[key]) for key in word_indices]\n",
    "\n",
    "d = {}\n",
    "for word in r:\n",
    "    d[word] = calculate_base_score(word)\n",
    "            \n",
    "sorted_scores = sorted(d.items(), key=lambda item: item[1], reverse = True)\n",
    "word_indices = {item[0]: word_indices[item[0]] for item in sorted_scores}\n",
    "word_indices = [(key, word_indices[key]) for key in word_indices]\n",
    "\n",
    "covered_tiles = set()\n",
    "selected_words = []\n",
    "unused_words = word_indices[:]\n",
    "previous_covered_count = 0\n",
    "while len(covered_tiles) < 16 and unused_words:\n",
    "    print(sorted(covered_tiles))\n",
    "#     for word in unused_words:\n",
    "#         print(word, calculate_base_score(word[0]), len(set(word[1]) & covered_tiles))\n",
    "    unused_words.sort(key=lambda x: (len(set(x[1]) & covered_tiles), -calculate_base_score(x[0])))\n",
    "    next_word, next_path = unused_words.pop(0)\n",
    "#     print(next_path, next_word)\n",
    "    new_covered_count = len(covered_tiles.union(set(next_path)))\n",
    "    if new_covered_count == previous_covered_count:\n",
    "        print(covered_tiles.union(set(next_path)))\n",
    "        break\n",
    "    \n",
    "    selected_words.append(next_word)\n",
    "    covered_tiles.update(next_path)\n",
    "    previous_covered_count = new_covered_count\n",
    "\n",
    "    # Remove this word from future consideration\n",
    "    unused_words = [word for word in unused_words if word[0] != next_word]\n",
    "\n",
    "# Step 3: Continue with descending score selection for any remaining words\n",
    "if len(covered_tiles) < 16 or len(selected_words) < len(word_indices):\n",
    "    for word, path in sorted_words:\n",
    "        if word not in selected_words:\n",
    "            selected_words.append(word)  # Add remaining high-scoring unused word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "9021e2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['donship',\n",
       " 'pinyons',\n",
       " 'satinpod',\n",
       " 'shiny',\n",
       " 'satiny',\n",
       " 'potash',\n",
       " 'dynast',\n",
       " 'snathe',\n",
       " 'astony',\n",
       " 'ashy',\n",
       " 'piths',\n",
       " 'novates',\n",
       " 'shy',\n",
       " 'savoy',\n",
       " 'vasty',\n",
       " 'donates',\n",
       " 'tiyns',\n",
       " 'shite',\n",
       " 'horns',\n",
       " 'stony',\n",
       " 'snath',\n",
       " 'nasty',\n",
       " 'pitons',\n",
       " 'ship',\n",
       " 'pontes',\n",
       " 'nitons',\n",
       " 'shit',\n",
       " 'hits',\n",
       " 'shin',\n",
       " 'eths',\n",
       " 'hest',\n",
       " 'hets',\n",
       " 'stay',\n",
       " 'hons',\n",
       " 'hots',\n",
       " 'say',\n",
       " 'yas',\n",
       " 'ash',\n",
       " 'pitas',\n",
       " 'hes',\n",
       " 'sty',\n",
       " 'she',\n",
       " 'savor',\n",
       " 'novas',\n",
       " 'votes',\n",
       " 'sh',\n",
       " 'pithy',\n",
       " 'porns',\n",
       " 'estop',\n",
       " 'satin',\n",
       " 'nites',\n",
       " 'donas',\n",
       " 'hydro',\n",
       " 'dotes',\n",
       " 'horny',\n",
       " 'pinyon',\n",
       " 'santo',\n",
       " 'antes',\n",
       " 'rotes',\n",
       " 'notes',\n",
       " 'seton',\n",
       " 'onset',\n",
       " 'etnas',\n",
       " 'rotas',\n",
       " 'nates',\n",
       " 'hypo',\n",
       " 'yodh',\n",
       " 'hyp',\n",
       " 'hyte',\n",
       " 'thy',\n",
       " 'hoy',\n",
       " 'dhoti',\n",
       " 'pits',\n",
       " 'atopy',\n",
       " 'porny',\n",
       " 'vats',\n",
       " 'vans',\n",
       " 'vase',\n",
       " 'atony',\n",
       " 'vast',\n",
       " 'pity',\n",
       " 'pyin',\n",
       " 'pith',\n",
       " 'piny',\n",
       " 'novate',\n",
       " 'nits',\n",
       " 'sati',\n",
       " 'stop',\n",
       " 'vas',\n",
       " 'dopy',\n",
       " 'hip',\n",
       " 'pons',\n",
       " 'navy',\n",
       " 'pots',\n",
       " 'yip',\n",
       " 'thin',\n",
       " 'tyin',\n",
       " 'typo',\n",
       " 'tiny',\n",
       " 'pony',\n",
       " 'donate',\n",
       " 'ropy',\n",
       " 'tiyn',\n",
       " 'tody',\n",
       " 'hin',\n",
       " 'hop',\n",
       " 'poh',\n",
       " 'doth',\n",
       " 'hit',\n",
       " 'yin',\n",
       " 'doty',\n",
       " 'ornate',\n",
       " 'dots',\n",
       " 'hi',\n",
       " 'yod',\n",
       " 'hod',\n",
       " 'tony',\n",
       " 'dons',\n",
       " 'horn',\n",
       " 'doh',\n",
       " 'its',\n",
       " 'toy',\n",
       " 'nth',\n",
       " 'the',\n",
       " 'any',\n",
       " 'yon',\n",
       " 'rho',\n",
       " 'nay',\n",
       " 'hon',\n",
       " 'het',\n",
       " 'noh',\n",
       " 'hot',\n",
       " 'piton',\n",
       " 'eth',\n",
       " 'ay',\n",
       " 'ho',\n",
       " 'oy',\n",
       " 'oh',\n",
       " 'he',\n",
       " 'yo',\n",
       " 'ovate',\n",
       " 'eh',\n",
       " 'ya',\n",
       " 'ants',\n",
       " 'tase',\n",
       " 'niton',\n",
       " 'tons',\n",
       " 'ates',\n",
       " 'tans',\n",
       " 'seta',\n",
       " 'sate',\n",
       " 'rots',\n",
       " 'snot',\n",
       " 'etas',\n",
       " 'san',\n",
       " 'tas',\n",
       " 'ons',\n",
       " 'tes',\n",
       " 'sat',\n",
       " 'set',\n",
       " 'est',\n",
       " 'pita',\n",
       " 'topi',\n",
       " 'vote',\n",
       " 'nova',\n",
       " 'pin',\n",
       " 'nip',\n",
       " 'drop',\n",
       " 'pit',\n",
       " 'tip',\n",
       " 'es',\n",
       " 'tav',\n",
       " 'anti',\n",
       " 'vat',\n",
       " 'pod',\n",
       " 'pi',\n",
       " 'ova',\n",
       " 'atop',\n",
       " 'avo',\n",
       " 'van',\n",
       " 'as',\n",
       " 'nite',\n",
       " 'roti',\n",
       " 'porn',\n",
       " 'nav',\n",
       " 'pot',\n",
       " 'top',\n",
       " 'dona',\n",
       " 'dote',\n",
       " 'nit',\n",
       " 'tin',\n",
       " 'rota',\n",
       " 'po',\n",
       " 'in',\n",
       " 'ti',\n",
       " 'nota',\n",
       " 'don',\n",
       " 'dor',\n",
       " 'op',\n",
       " 'dot',\n",
       " 'note',\n",
       " 'rote',\n",
       " 'torn',\n",
       " 'ante',\n",
       " 'tod',\n",
       " 'etna',\n",
       " 'rod',\n",
       " 'it',\n",
       " 'nod',\n",
       " 'tan',\n",
       " 'ton',\n",
       " 'od',\n",
       " 'nor',\n",
       " 'tor',\n",
       " 'rot',\n",
       " 'not',\n",
       " 'ate',\n",
       " 'do',\n",
       " 'ant',\n",
       " 'eta',\n",
       " 'on',\n",
       " 'an',\n",
       " 'no',\n",
       " 'na',\n",
       " 'te',\n",
       " 'at',\n",
       " 'or',\n",
       " 'to',\n",
       " 'et',\n",
       " 'ta']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e75c9a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'petitions': [(0, 1),\n",
       "  (1, 1),\n",
       "  (2, 2),\n",
       "  (1, 3),\n",
       "  (0, 3),\n",
       "  (1, 2),\n",
       "  (2, 1),\n",
       "  (1, 0),\n",
       "  (2, 0)],\n",
       " 'petition': [(0, 1), (1, 1), (2, 2), (1, 3), (0, 3), (1, 2), (2, 1), (1, 0)],\n",
       " 'nittiest': [(2, 3), (1, 3), (0, 3), (0, 2), (1, 2), (1, 1), (2, 0), (3, 1)],\n",
       " 'pinites': [(0, 1), (1, 2), (2, 3), (1, 3), (2, 2), (1, 1), (2, 0)],\n",
       " 'pintoes': [(0, 1), (1, 2), (2, 3), (2, 2), (2, 1), (1, 1), (2, 0)],\n",
       " 'titties': [(2, 2), (1, 3), (0, 3), (0, 2), (1, 2), (1, 1), (2, 0)],\n",
       " 'tiniest': [(2, 2), (1, 3), (2, 3), (1, 2), (1, 1), (2, 0), (3, 1)],\n",
       " 'notions': [(2, 3), (3, 3), (2, 2), (1, 2), (2, 1), (1, 0), (2, 0)],\n",
       " 'intones': [(1, 3), (2, 3), (2, 2), (2, 1), (1, 0), (1, 1), (2, 0)],\n",
       " 'toniest': [(2, 2), (3, 3), (2, 3), (1, 2), (1, 1), (2, 0), (3, 1)],\n",
       " 'oftest': [(3, 3), (3, 2), (2, 2), (1, 1), (2, 0), (3, 1)],\n",
       " 'soften': [(2, 0), (2, 1), (3, 2), (2, 2), (1, 1), (1, 0)],\n",
       " 'softie': [(2, 0), (2, 1), (3, 2), (2, 2), (1, 2), (1, 1)],\n",
       " 'pitots': [(0, 1), (1, 2), (2, 2), (2, 1), (3, 1), (2, 0)],\n",
       " 'pintos': [(0, 1), (1, 2), (2, 3), (2, 2), (2, 1), (2, 0)],\n",
       " 'tenpin': [(2, 2), (1, 1), (1, 0), (0, 1), (1, 2), (2, 3)],\n",
       " 'pinite': [(0, 1), (1, 2), (2, 3), (1, 3), (2, 2), (1, 1)],\n",
       " 'pitons': [(0, 1), (1, 2), (2, 2), (2, 1), (1, 0), (2, 0)],\n",
       " 'onions': [(3, 3), (2, 3), (1, 2), (2, 1), (1, 0), (2, 0)],\n",
       " 'teston': [(2, 2), (1, 1), (2, 0), (3, 1), (2, 1), (1, 0)],\n",
       " 'nitons': [(2, 3), (1, 3), (2, 2), (2, 1), (1, 0), (2, 0)],\n",
       " 'inions': [(1, 3), (2, 3), (1, 2), (2, 1), (1, 0), (2, 0)],\n",
       " 'stotin': [(2, 0), (3, 1), (2, 1), (2, 2), (1, 3), (2, 3)],\n",
       " 'tittie': [(2, 2), (1, 3), (0, 3), (0, 2), (1, 2), (1, 1)],\n",
       " 'notion': [(2, 3), (3, 3), (2, 2), (1, 2), (2, 1), (1, 0)],\n",
       " 'intone': [(1, 3), (2, 3), (2, 2), (2, 1), (1, 0), (1, 1)],\n",
       " 'otiose': [(3, 3), (2, 2), (1, 2), (2, 1), (2, 0), (1, 1)],\n",
       " 'tofts': [(2, 2), (3, 3), (3, 2), (3, 1), (2, 0)],\n",
       " 'infos': [(1, 3), (2, 3), (3, 2), (2, 1), (2, 0)],\n",
       " 'often': [(3, 3), (3, 2), (2, 2), (1, 1), (1, 0)],\n",
       " 'votes': [(3, 0), (2, 1), (2, 2), (1, 1), (2, 0)],\n",
       " 'pitot': [(0, 1), (1, 2), (2, 2), (2, 1), (3, 1)],\n",
       " 'peens': [(0, 1), (1, 1), (0, 0), (1, 0), (2, 0)],\n",
       " 'peons': [(0, 1), (1, 1), (2, 1), (1, 0), (2, 0)],\n",
       " 'petto': [(0, 1), (1, 1), (2, 2), (3, 1), (2, 1)],\n",
       " 'pesto': [(0, 1), (1, 1), (2, 0), (3, 1), (2, 1)],\n",
       " 'petti': [(0, 1), (1, 1), (0, 2), (0, 3), (1, 3)],\n",
       " 'pinot': [(0, 1), (1, 2), (2, 3), (3, 3), (2, 2)],\n",
       " 'penes': [(0, 1), (0, 0), (1, 0), (1, 1), (2, 0)],\n",
       " 'pinto': [(0, 1), (1, 2), (2, 3), (2, 2), (3, 3)],\n",
       " 'piton': [(0, 1), (1, 2), (2, 2), (3, 3), (2, 3)],\n",
       " 'pions': [(0, 1), (1, 2), (2, 1), (1, 0), (2, 0)],\n",
       " 'petit': [(0, 1), (1, 1), (2, 2), (1, 3), (0, 3)],\n",
       " 'ottos': [(3, 3), (2, 2), (3, 1), (2, 1), (2, 0)],\n",
       " 'totes': [(3, 1), (2, 1), (2, 2), (1, 1), (2, 0)],\n",
       " 'niton': [(2, 3), (1, 3), (2, 2), (2, 1), (1, 0)],\n",
       " 'onion': [(3, 3), (2, 3), (1, 2), (2, 1), (1, 0)],\n",
       " 'notes': [(2, 3), (3, 3), (2, 2), (1, 1), (2, 0)],\n",
       " 'seton': [(2, 0), (1, 1), (2, 2), (3, 3), (2, 3)],\n",
       " 'stone': [(2, 0), (3, 1), (2, 1), (1, 0), (1, 1)],\n",
       " 'onset': [(2, 1), (1, 0), (2, 0), (1, 1), (2, 2)],\n",
       " 'teens': [(2, 2), (1, 1), (0, 0), (1, 0), (2, 0)],\n",
       " 'inion': [(1, 3), (2, 3), (1, 2), (2, 1), (1, 0)],\n",
       " 'nites': [(2, 3), (1, 3), (2, 2), (1, 1), (2, 0)],\n",
       " 'netts': [(1, 0), (1, 1), (2, 2), (3, 1), (2, 0)],\n",
       " 'tones': [(3, 1), (2, 1), (1, 0), (1, 1), (2, 0)],\n",
       " 'vote': [(3, 0), (2, 1), (2, 2), (1, 1)],\n",
       " 'info': [(1, 3), (2, 3), (3, 2), (3, 3)],\n",
       " 'foes': [(3, 2), (2, 1), (1, 1), (2, 0)],\n",
       " 'fons': [(3, 2), (2, 1), (1, 0), (2, 0)],\n",
       " 'soft': [(2, 0), (2, 1), (3, 2), (3, 1)],\n",
       " 'font': [(3, 2), (3, 3), (2, 3), (2, 2)],\n",
       " 'voes': [(3, 0), (2, 1), (1, 1), (2, 0)],\n",
       " 'toft': [(3, 1), (2, 1), (3, 2), (2, 2)],\n",
       " 'foin': [(3, 2), (2, 1), (1, 2), (2, 3)],\n",
       " 'foe': [(3, 2), (2, 1), (1, 1)],\n",
       " 'peon': [(0, 1), (1, 1), (2, 1), (1, 0)],\n",
       " 'peso': [(0, 1), (1, 1), (2, 0), (2, 1)],\n",
       " 'pint': [(0, 1), (1, 2), (2, 3), (2, 2)],\n",
       " 'voe': [(3, 0), (2, 1), (1, 1)],\n",
       " 'fon': [(3, 2), (3, 3), (2, 3)],\n",
       " 'seep': [(2, 0), (1, 1), (0, 0), (0, 1)],\n",
       " 'oft': [(3, 3), (3, 2), (3, 1)],\n",
       " 'pees': [(0, 1), (0, 0), (1, 1), (2, 0)],\n",
       " 'pion': [(0, 1), (1, 2), (2, 1), (1, 0)],\n",
       " 'pein': [(0, 1), (1, 1), (1, 2), (2, 3)],\n",
       " 'pest': [(0, 1), (1, 1), (2, 0), (3, 1)],\n",
       " 'peen': [(0, 1), (1, 1), (0, 0), (1, 0)],\n",
       " 'pens': [(0, 1), (1, 1), (1, 0), (2, 0)],\n",
       " 'pies': [(0, 1), (1, 2), (1, 1), (2, 0)],\n",
       " 'neep': [(1, 0), (1, 1), (0, 0), (0, 1)],\n",
       " 'sept': [(2, 0), (1, 1), (0, 1), (0, 2)],\n",
       " 'pes': [(0, 1), (1, 1), (2, 0)],\n",
       " 'pee': [(0, 1), (1, 1), (0, 0)],\n",
       " 'pie': [(0, 1), (1, 2), (1, 1)],\n",
       " 'of': [(3, 3), (3, 2)],\n",
       " 'pen': [(0, 1), (1, 1), (1, 0)],\n",
       " 'pin': [(0, 1), (1, 2), (2, 3)],\n",
       " 'pet': [(0, 1), (1, 1), (2, 2)],\n",
       " 'nip': [(2, 3), (1, 2), (0, 1)],\n",
       " 'pit': [(0, 1), (1, 2), (2, 2)],\n",
       " 'tip': [(2, 2), (1, 2), (0, 1)],\n",
       " 'tint': [(0, 3), (1, 3), (2, 3), (2, 2)],\n",
       " 'tens': [(2, 2), (1, 1), (1, 0), (2, 0)],\n",
       " 'ions': [(1, 2), (2, 1), (1, 0), (2, 0)],\n",
       " 'toit': [(3, 1), (2, 1), (1, 2), (2, 2)],\n",
       " 'sene': [(2, 0), (1, 1), (1, 0), (0, 0)],\n",
       " 'ones': [(2, 1), (1, 0), (1, 1), (2, 0)],\n",
       " 'toes': [(3, 1), (2, 1), (1, 1), (2, 0)],\n",
       " 'tots': [(2, 2), (2, 1), (3, 1), (2, 0)],\n",
       " 'inti': [(1, 3), (2, 3), (2, 2), (1, 2)],\n",
       " 'sett': [(2, 0), (1, 1), (2, 2), (3, 1)],\n",
       " 'eons': [(1, 1), (2, 1), (1, 0), (2, 0)],\n",
       " 'tons': [(3, 1), (2, 1), (1, 0), (2, 0)],\n",
       " 'pi': [(0, 1), (1, 2)],\n",
       " 'tone': [(3, 1), (2, 1), (1, 0), (1, 1)],\n",
       " 'into': [(1, 3), (2, 3), (2, 2), (3, 3)],\n",
       " 'pe': [(0, 1), (1, 1)],\n",
       " 'stot': [(2, 0), (3, 1), (2, 1), (2, 2)],\n",
       " 'tost': [(2, 2), (2, 1), (2, 0), (3, 1)],\n",
       " 'tote': [(3, 1), (2, 1), (2, 2), (1, 1)],\n",
       " 'nose': [(1, 0), (2, 1), (2, 0), (1, 1)],\n",
       " 'ties': [(2, 2), (1, 2), (1, 1), (2, 0)],\n",
       " 'sone': [(2, 0), (2, 1), (1, 0), (1, 1)],\n",
       " 'note': [(2, 3), (3, 3), (2, 2), (1, 1)],\n",
       " 'otto': [(3, 3), (2, 2), (3, 1), (2, 1)],\n",
       " 'onto': [(3, 3), (2, 3), (2, 2), (2, 1)],\n",
       " 'teen': [(2, 2), (1, 1), (0, 0), (1, 0)],\n",
       " 'titi': [(2, 2), (1, 3), (0, 3), (1, 2)],\n",
       " 'nest': [(1, 0), (1, 1), (2, 0), (3, 1)],\n",
       " 'snot': [(2, 0), (1, 0), (2, 1), (3, 1)],\n",
       " 'test': [(2, 2), (1, 1), (2, 0), (3, 1)],\n",
       " 'nett': [(1, 0), (1, 1), (2, 2), (3, 1)],\n",
       " 'seen': [(2, 0), (1, 1), (0, 0), (1, 0)],\n",
       " 'nite': [(2, 3), (1, 3), (2, 2), (1, 1)],\n",
       " 'tein': [(2, 2), (1, 1), (1, 2), (2, 3)],\n",
       " 'noes': [(1, 0), (2, 1), (1, 1), (2, 0)],\n",
       " 'esne': [(1, 1), (2, 0), (1, 0), (0, 0)],\n",
       " 'nee': [(1, 0), (1, 1), (0, 0)],\n",
       " 'tot': [(3, 1), (2, 1), (2, 2)],\n",
       " 'ton': [(3, 1), (2, 1), (1, 0)],\n",
       " 'ose': [(2, 1), (2, 0), (1, 1)],\n",
       " 'tie': [(2, 2), (1, 2), (1, 1)],\n",
       " 'nos': [(1, 0), (2, 1), (2, 0)],\n",
       " 'son': [(2, 0), (2, 1), (1, 0)],\n",
       " 'sei': [(2, 0), (1, 1), (1, 2)],\n",
       " 'sen': [(2, 0), (1, 1), (1, 0)],\n",
       " 'net': [(1, 0), (1, 1), (2, 2)],\n",
       " 'ens': [(1, 1), (1, 0), (2, 0)],\n",
       " 'ons': [(2, 1), (1, 0), (2, 0)],\n",
       " 'tee': [(2, 2), (1, 1), (0, 0)],\n",
       " 'ion': [(1, 2), (2, 1), (1, 0)],\n",
       " 'not': [(2, 3), (3, 3), (2, 2)],\n",
       " 'sot': [(2, 0), (2, 1), (3, 1)],\n",
       " 'tes': [(2, 2), (1, 1), (2, 0)],\n",
       " 'toe': [(3, 1), (2, 1), (1, 1)],\n",
       " 'one': [(2, 1), (1, 0), (1, 1)],\n",
       " 'tet': [(2, 2), (1, 1), (0, 2)],\n",
       " 'oes': [(2, 1), (1, 1), (2, 0)],\n",
       " 'set': [(2, 0), (1, 1), (2, 2)],\n",
       " 'tit': [(2, 2), (1, 3), (0, 3)],\n",
       " 'eon': [(1, 1), (2, 1), (1, 0)],\n",
       " 'nit': [(2, 3), (1, 3), (2, 2)],\n",
       " 'see': [(2, 0), (1, 1), (0, 0)],\n",
       " 'est': [(1, 1), (2, 0), (3, 1)],\n",
       " 'ten': [(2, 2), (1, 1), (1, 0)],\n",
       " 'tin': [(2, 2), (1, 3), (2, 3)],\n",
       " 'on': [(3, 3), (2, 3)],\n",
       " 'es': [(1, 1), (2, 0)],\n",
       " 'oi': [(2, 1), (1, 2)],\n",
       " 'in': [(1, 3), (2, 3)],\n",
       " 'so': [(2, 0), (2, 1)],\n",
       " 'ti': [(2, 2), (1, 3)],\n",
       " 'no': [(2, 3), (3, 3)],\n",
       " 'te': [(2, 2), (1, 1)],\n",
       " 'oe': [(2, 1), (1, 1)],\n",
       " 'to': [(3, 1), (2, 1)],\n",
       " 'os': [(2, 1), (2, 0)],\n",
       " 'et': [(1, 1), (2, 2)],\n",
       " 'it': [(1, 3), (2, 2)],\n",
       " 'ne': [(1, 0), (1, 1)],\n",
       " 'en': [(1, 1), (1, 0)]}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(word_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a2b735a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('donship', 114),\n",
       " ('pinyons', 111),\n",
       " ('shiny', 102),\n",
       " ('satinpod', 99),\n",
       " ('satiny', 87),\n",
       " ('potash', 87),\n",
       " ('dynast', 84),\n",
       " ('snathe', 81),\n",
       " ('astony', 81),\n",
       " ('ashy', 78),\n",
       " ('piths', 75),\n",
       " ('novates', 75),\n",
       " ('shy', 75),\n",
       " ('savoy', 72),\n",
       " ('vasty', 72),\n",
       " ('donates', 69),\n",
       " ('tiyns', 69),\n",
       " ('shite', 69),\n",
       " ('horns', 63),\n",
       " ('stony', 63),\n",
       " ('snath', 63),\n",
       " ('nasty', 63),\n",
       " ('pitons', 60),\n",
       " ('ship', 57),\n",
       " ('pontes', 54),\n",
       " ('nitons', 54),\n",
       " ('shit', 51),\n",
       " ('hits', 51),\n",
       " ('shin', 51),\n",
       " ('eths', 45),\n",
       " ('hest', 45),\n",
       " ('hets', 45),\n",
       " ('stay', 45),\n",
       " ('hons', 45),\n",
       " ('hots', 45),\n",
       " ('say', 42),\n",
       " ('yas', 42),\n",
       " ('ash', 42),\n",
       " ('pitas', 42),\n",
       " ('hes', 42),\n",
       " ('sty', 42),\n",
       " ('she', 42),\n",
       " ('savor', 39),\n",
       " ('novas', 39),\n",
       " ('votes', 39),\n",
       " ('sh', 39),\n",
       " ('pithy', 36),\n",
       " ('porns', 36),\n",
       " ('estop', 36),\n",
       " ('satin', 36),\n",
       " ('nites', 36),\n",
       " ('donas', 33),\n",
       " ('hydro', 33),\n",
       " ('dotes', 33),\n",
       " ('horny', 32),\n",
       " ('pinyon', 31),\n",
       " ('santo', 30),\n",
       " ('antes', 30),\n",
       " ('rotes', 30),\n",
       " ('notes', 30),\n",
       " ('seton', 30),\n",
       " ('onset', 30),\n",
       " ('etnas', 30),\n",
       " ('rotas', 30),\n",
       " ('nates', 30),\n",
       " ('hypo', 28),\n",
       " ('yodh', 27),\n",
       " ('hyp', 27),\n",
       " ('hyte', 26),\n",
       " ('thy', 25),\n",
       " ('hoy', 25),\n",
       " ('dhoti', 24),\n",
       " ('pits', 24),\n",
       " ('atopy', 23),\n",
       " ('porny', 23),\n",
       " ('vats', 21),\n",
       " ('vans', 21),\n",
       " ('vase', 21),\n",
       " ('atony', 21),\n",
       " ('vast', 21),\n",
       " ('pity', 19),\n",
       " ('pyin', 19),\n",
       " ('pith', 19),\n",
       " ('piny', 19),\n",
       " ('novate', 19),\n",
       " ('nits', 18),\n",
       " ('sati', 18),\n",
       " ('stop', 18),\n",
       " ('vas', 18),\n",
       " ('dopy', 18),\n",
       " ('hip', 18),\n",
       " ('pons', 18),\n",
       " ('navy', 18),\n",
       " ('pots', 18),\n",
       " ('yip', 18),\n",
       " ('thin', 17),\n",
       " ('tyin', 17),\n",
       " ('typo', 17),\n",
       " ('tiny', 17),\n",
       " ('pony', 17),\n",
       " ('donate', 17),\n",
       " ('ropy', 17),\n",
       " ('tiyn', 17),\n",
       " ('tody', 16),\n",
       " ('hin', 16),\n",
       " ('hop', 16),\n",
       " ('poh', 16),\n",
       " ('doth', 16),\n",
       " ('hit', 16),\n",
       " ('yin', 16),\n",
       " ('doty', 16),\n",
       " ('ornate', 16),\n",
       " ('dots', 15),\n",
       " ('hi', 15),\n",
       " ('yod', 15),\n",
       " ('hod', 15),\n",
       " ('tony', 15),\n",
       " ('dons', 15),\n",
       " ('horn', 15),\n",
       " ('doh', 15),\n",
       " ('its', 15),\n",
       " ('toy', 14),\n",
       " ('nth', 14),\n",
       " ('the', 14),\n",
       " ('any', 14),\n",
       " ('yon', 14),\n",
       " ('rho', 14),\n",
       " ('nay', 14),\n",
       " ('hon', 14),\n",
       " ('het', 14),\n",
       " ('noh', 14),\n",
       " ('hot', 14),\n",
       " ('piton', 14),\n",
       " ('eth', 14),\n",
       " ('ay', 13),\n",
       " ('ho', 13),\n",
       " ('oy', 13),\n",
       " ('oh', 13),\n",
       " ('he', 13),\n",
       " ('yo', 13),\n",
       " ('ovate', 13),\n",
       " ('eh', 13),\n",
       " ('ya', 13),\n",
       " ('ants', 12),\n",
       " ('tase', 12),\n",
       " ('niton', 12),\n",
       " ('tons', 12),\n",
       " ('ates', 12),\n",
       " ('tans', 12),\n",
       " ('seta', 12),\n",
       " ('sate', 12),\n",
       " ('rots', 12),\n",
       " ('snot', 12),\n",
       " ('etas', 12),\n",
       " ('san', 9),\n",
       " ('tas', 9),\n",
       " ('ons', 9),\n",
       " ('tes', 9),\n",
       " ('sat', 9),\n",
       " ('set', 9),\n",
       " ('est', 9),\n",
       " ('pita', 8),\n",
       " ('topi', 8),\n",
       " ('vote', 7),\n",
       " ('nova', 7),\n",
       " ('pin', 7),\n",
       " ('nip', 7),\n",
       " ('drop', 7),\n",
       " ('pit', 7),\n",
       " ('tip', 7),\n",
       " ('es', 6),\n",
       " ('tav', 6),\n",
       " ('anti', 6),\n",
       " ('vat', 6),\n",
       " ('pod', 6),\n",
       " ('pi', 6),\n",
       " ('ova', 6),\n",
       " ('atop', 6),\n",
       " ('avo', 6),\n",
       " ('van', 6),\n",
       " ('as', 6),\n",
       " ('nite', 6),\n",
       " ('roti', 6),\n",
       " ('porn', 6),\n",
       " ('nav', 6),\n",
       " ('pot', 5),\n",
       " ('top', 5),\n",
       " ('dona', 5),\n",
       " ('dote', 5),\n",
       " ('nit', 5),\n",
       " ('tin', 5),\n",
       " ('rota', 4),\n",
       " ('po', 4),\n",
       " ('in', 4),\n",
       " ('ti', 4),\n",
       " ('nota', 4),\n",
       " ('don', 4),\n",
       " ('dor', 4),\n",
       " ('op', 4),\n",
       " ('dot', 4),\n",
       " ('note', 4),\n",
       " ('rote', 4),\n",
       " ('torn', 4),\n",
       " ('ante', 4),\n",
       " ('tod', 4),\n",
       " ('etna', 4),\n",
       " ('rod', 4),\n",
       " ('it', 4),\n",
       " ('nod', 4),\n",
       " ('tan', 3),\n",
       " ('ton', 3),\n",
       " ('od', 3),\n",
       " ('nor', 3),\n",
       " ('tor', 3),\n",
       " ('rot', 3),\n",
       " ('not', 3),\n",
       " ('ate', 3),\n",
       " ('do', 3),\n",
       " ('ant', 3),\n",
       " ('eta', 3),\n",
       " ('on', 2),\n",
       " ('an', 2),\n",
       " ('no', 2),\n",
       " ('na', 2),\n",
       " ('te', 2),\n",
       " ('at', 2),\n",
       " ('or', 2),\n",
       " ('to', 2),\n",
       " ('et', 2),\n",
       " ('ta', 2)]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ef10aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
